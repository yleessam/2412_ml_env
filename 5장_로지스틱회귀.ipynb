{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dataset_scaled = scaler.fit_transform(dataset.data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset_scaled, dataset.target, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9766081871345029, roc_auc : 0.9715608465608465 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_preds = lr_clf.predict(X_test)\n",
    "lr_preds_proba = lr_clf.predict_log_proba(X_test)[:,1]\n",
    "\n",
    "print(f'accuracy : {accuracy_score(y_test, lr_preds)}, roc_auc : {roc_auc_score(y_test, lr_preds)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " solver lbfgs :: accuracy : 0.9766081871345029, roc_auc : 0.9715608465608465 \n",
      " solver liblinear :: accuracy : 0.9824561403508771, roc_auc : 0.9794973544973544 \n",
      " solver newton-cg :: accuracy : 0.9766081871345029, roc_auc : 0.9715608465608465 \n",
      " solver sag :: accuracy : 0.9824561403508771, roc_auc : 0.9794973544973544 \n",
      " solver saga :: accuracy : 0.9824561403508771, roc_auc : 0.9794973544973544 \n"
     ]
    }
   ],
   "source": [
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga']\n",
    "\n",
    "for solver in solvers:\n",
    "    lr_clf = LogisticRegression(solver=solver, max_iter=600)\n",
    "    lr_clf.fit(X_train, y_train)\n",
    "    lr_preds = lr_clf.predict(X_test)\n",
    "    lr_preds_proba = lr_clf.predict_log_proba(X_test)[:,1]\n",
    "\n",
    "    print(f' solver {solver} :: accuracy : {accuracy_score(y_test, lr_preds)}, roc_auc : {roc_auc_score(y_test, lr_preds)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "liblinear, saga : l1, l2\n",
    "lbfgs, newton-cg, sag : l2\n",
    "\n",
    "C: alpha 역수 > 작을 수록 규제가 크다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter : {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}, Best_accuracy 0.9789102385593614\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# params = {\n",
    "#     'solver': ['liblinear', 'lbfgs'],\n",
    "#     'penalty': ['l2', 'l1'],\n",
    "#     'C' : [0.01, 0.1, 1, 5, 10, ]\n",
    "# }\n",
    "params = [\n",
    "    {'solver': ['liblinear'], 'penalty': ['l1', 'l2'], 'C': [0.01, 0.1, 1, 5, 10, 100]},\n",
    "    {'solver': ['lbfgs', 'newton-cg'], 'penalty': ['l2'], 'C': [0.1, 1, 5, 10, 100]}\n",
    "]\n",
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "grid_clf = GridSearchCV(lr_clf, param_grid=params, scoring='accuracy', cv=3)\n",
    "grid_clf.fit(dataset_scaled, dataset.target)\n",
    "print(f'Best parameter : {grid_clf.best_params_}, Best_accuracy {grid_clf.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameter : {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}, Best_accuracy 0.9648565859092174\n",
    "Best parameter : {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}, Best_accuracy 0.9789102385593614\n",
    "\n",
    "accuracy : 0.9532163742690059, roc_auc : 0.9497354497354497 \n",
    "accuracy : 0.9707602339181286, roc_auc : 0.9636243386243386 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9707602339181286, roc_auc : 0.9636243386243386 \n"
     ]
    }
   ],
   "source": [
    "best_param = grid_clf.best_params_\n",
    "\n",
    "best_lr_clf = LogisticRegression(**best_param)\n",
    "best_lr_clf.fit(X_train, y_train)\n",
    "\n",
    "lr_preds = best_lr_clf.predict(X_test)\n",
    "lr_preds_proba = best_lr_clf.predict_log_proba(X_test)[:,1]\n",
    "\n",
    "print(f'accuracy : {accuracy_score(y_test, lr_preds)}, roc_auc : {roc_auc_score(y_test, lr_preds)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model : RandomForestRegressor(n_estimators=1000, random_state=0) avg_r2 : 0.6266886861376235  avg_rmse : 4.422538982804892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# 보스턴 데이터 세트 로드\n",
    "boston = load_boston()\n",
    "bostonDF = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "\n",
    "bostonDF['PRICE'] = boston.target\n",
    "y_target = bostonDF['PRICE']\n",
    "X_data = bostonDF.drop(['PRICE'], axis=1,inplace=False)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "eval_model(rf,X_data, y_target )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, X_data, y_target, cv=5):\n",
    "    neg_mse_scores = cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "    r2_scores = cross_val_score(model,  X_data, y_target, scoring='r2', cv=5)\n",
    "    avg_r2 = np.mean(r2_scores)\n",
    "    print(f'model : {model} avg_r2 : {avg_r2}  avg_rmse : {avg_rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model : DecisionTreeRegressor(max_depth=4, random_state=0) avg_r2 : 0.17632964818238434  avg_rmse : 5.977957424580515\n",
      "model : RandomForestRegressor(n_estimators=1000, random_state=0) avg_r2 : 0.6266886861376235  avg_rmse : 4.422538982804892\n",
      "model : GradientBoostingRegressor(n_estimators=1000, random_state=0) avg_r2 : 0.6599942147734554  avg_rmse : 4.26899822168126\n",
      "model : XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None) avg_r2 : 0.6460596877333733  avg_rmse : 4.251080362834295\n",
      "model : LGBMRegressor(n_estimators=1000) avg_r2 : 0.562589104761876  avg_rmse : 4.646441191925675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "dt_reg = DecisionTreeRegressor(random_state=0, max_depth=4)\n",
    "rf_reg = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "gb_reg = GradientBoostingRegressor(random_state=0, n_estimators=1000)\n",
    "xgb_reg = XGBRegressor(n_estimators=1000)\n",
    "lgb_reg = LGBMRegressor(n_estimators=1000)\n",
    "\n",
    "# 트리 기반의 회귀 모델을 반복하면서 평가 수행 \n",
    "models = [dt_reg, rf_reg, gb_reg, xgb_reg, lgb_reg]\n",
    "for model in models:  \n",
    "    eval_model(model, X_data, y_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
