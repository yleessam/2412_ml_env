{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "#분류기 1\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros( (X.shape[0],1))\n",
    "        for i in range(X.shape[0]):  #sex==1, survived=0으로 예측, 아니면 1로 예측\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 피처 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행.\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 데이터 전처리 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df) \n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ylee\\AppData\\Local\\Temp\\ipykernel_31564\\2334727292.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
      "C:\\Users\\ylee\\AppData\\Local\\Temp\\ipykernel_31564\\2334727292.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Cabin'].fillna('N', inplace=True)\n",
      "C:\\Users\\ylee\\AppData\\Local\\Temp\\ipykernel_31564\\2334727292.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Embarked'].fillna('N', inplace=True)\n",
      "C:\\Users\\ylee\\AppData\\Local\\Temp\\ipykernel_31564\\2334727292.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Fare'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# data load\n",
    "\n",
    "titanic_df = pd.read_csv('titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "#전처리\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "#데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df,y_titanic_df, test_size=0.2, random_state=0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성& 학습\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7877094972067039"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pred = myclf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오차행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92, 18],\n",
       "       [20, 49]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, my_pred) #row : 실제값, col : 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7313432835820896, 0.7101449275362319)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_test, my_pred), recall_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MNIST dataset - 손글씨 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X,y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.zeros( (len(X), 1), dtype=bool )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits \n",
    "\n",
    "\n",
    "#Mnist dataset\n",
    "digits = load_digits()\n",
    "digits.data.shape  #1797개 샘플, 64개 특성 - 8x8 픽셀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 149 페이지의 MyFakeClassifier 를 이용한 정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차행렬 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       " 0       3    1  22.0      1      0   7.2500      7         3\n",
       " 1       1    0  38.0      1      0  71.2833      2         0\n",
       " 2       3    0  26.0      0      0   7.9250      7         3\n",
       " 3       1    0  35.0      1      0  53.1000      2         3\n",
       " 4       3    1  35.0      0      0   8.0500      7         3,\n",
       " 0    0\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    0\n",
       " Name: Survived, dtype: int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#titanic_df\n",
    "X_titanic_df.head(), y_titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정밀도, 재현율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리\n",
    "#X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p156\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "\n",
    "    print(confusion)\n",
    "    print('*'*20)\n",
    "    print(accuracy, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104  14]\n",
      " [ 13  48]]\n",
      "********************\n",
      "0.8491620111731844 0.7741935483870968 0.7868852459016393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ylee\\anaconda3\\envs\\ml_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#로지스틱회귀 분류모델 생성\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "\n",
    "#정확도, 정밀도, 재현율\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46157033, 0.53842967, 1.        ],\n",
       "       [0.87858018, 0.12141982, 0.        ],\n",
       "       [0.87720739, 0.12279261, 0.        ],\n",
       "       [0.88280949, 0.11719051, 0.        ],\n",
       "       [0.85494605, 0.14505395, 0.        ],\n",
       "       [0.88229211, 0.11770789, 0.        ],\n",
       "       [0.88834807, 0.11165193, 0.        ],\n",
       "       [0.20906827, 0.79093173, 1.        ],\n",
       "       [0.78247388, 0.21752612, 0.        ],\n",
       "       [0.3700126 , 0.6299874 , 1.        ],\n",
       "       [0.89987508, 0.10012492, 0.        ],\n",
       "       [0.87473432, 0.12526568, 0.        ],\n",
       "       [0.87720145, 0.12279855, 0.        ],\n",
       "       [0.88830249, 0.11169751, 0.        ],\n",
       "       [0.4352521 , 0.5647479 , 1.        ],\n",
       "       [0.85882876, 0.14117124, 0.        ],\n",
       "       [0.90367864, 0.09632136, 0.        ],\n",
       "       [0.7331396 , 0.2668604 , 0.        ],\n",
       "       [0.72419586, 0.27580414, 0.        ],\n",
       "       [0.17249557, 0.82750443, 1.        ],\n",
       "       [0.75336692, 0.24663308, 0.        ],\n",
       "       [0.61949682, 0.38050318, 0.        ],\n",
       "       [0.85445473, 0.14554527, 0.        ],\n",
       "       [0.81505188, 0.18494812, 0.        ],\n",
       "       [0.88793436, 0.11206564, 0.        ],\n",
       "       [0.76529405, 0.23470595, 0.        ],\n",
       "       [0.8596729 , 0.1403271 , 0.        ],\n",
       "       [0.92604627, 0.07395373, 0.        ],\n",
       "       [0.71927624, 0.28072376, 0.        ],\n",
       "       [0.69484495, 0.30515505, 0.        ],\n",
       "       [0.05265558, 0.94734442, 1.        ],\n",
       "       [0.18229482, 0.81770518, 1.        ],\n",
       "       [0.87328982, 0.12671018, 0.        ],\n",
       "       [0.1743638 , 0.8256362 , 1.        ],\n",
       "       [0.6003721 , 0.3996279 , 0.        ],\n",
       "       [0.76529405, 0.23470595, 0.        ],\n",
       "       [0.92766436, 0.07233564, 0.        ],\n",
       "       [0.38847204, 0.61152796, 1.        ],\n",
       "       [0.94695715, 0.05304285, 0.        ],\n",
       "       [0.89602871, 0.10397129, 0.        ],\n",
       "       [0.64961325, 0.35038675, 0.        ],\n",
       "       [0.91683912, 0.08316088, 0.        ],\n",
       "       [0.17792768, 0.82207232, 1.        ],\n",
       "       [0.29207858, 0.70792142, 1.        ],\n",
       "       [0.3696757 , 0.6303243 , 1.        ],\n",
       "       [0.36965953, 0.63034047, 1.        ],\n",
       "       [0.0813501 , 0.9186499 , 1.        ],\n",
       "       [0.64363299, 0.35636701, 0.        ],\n",
       "       [0.05106096, 0.94893904, 1.        ],\n",
       "       [0.88790006, 0.11209994, 0.        ],\n",
       "       [0.40580132, 0.59419868, 1.        ],\n",
       "       [0.88830249, 0.11169751, 0.        ],\n",
       "       [0.867079  , 0.132921  , 0.        ],\n",
       "       [0.27497994, 0.72502006, 1.        ],\n",
       "       [0.69027433, 0.30972567, 0.        ],\n",
       "       [0.80343213, 0.19656787, 0.        ],\n",
       "       [0.77351249, 0.22648751, 0.        ],\n",
       "       [0.87720636, 0.12279364, 0.        ],\n",
       "       [0.84560642, 0.15439358, 0.        ],\n",
       "       [0.56729433, 0.43270567, 0.        ],\n",
       "       [0.7195661 , 0.2804339 , 0.        ],\n",
       "       [0.89906013, 0.10093987, 0.        ],\n",
       "       [0.45339929, 0.54660071, 1.        ],\n",
       "       [0.48643348, 0.51356652, 1.        ],\n",
       "       [0.55547778, 0.44452222, 0.        ],\n",
       "       [0.90536831, 0.09463169, 0.        ],\n",
       "       [0.33299009, 0.66700991, 1.        ],\n",
       "       [0.40578896, 0.59421104, 1.        ],\n",
       "       [0.04807613, 0.95192387, 1.        ],\n",
       "       [0.85215824, 0.14784176, 0.        ],\n",
       "       [0.87082742, 0.12917258, 0.        ],\n",
       "       [0.83132168, 0.16867832, 0.        ],\n",
       "       [0.89602648, 0.10397352, 0.        ],\n",
       "       [0.05207701, 0.94792299, 1.        ],\n",
       "       [0.8012554 , 0.1987446 , 0.        ],\n",
       "       [0.88830249, 0.11169751, 0.        ],\n",
       "       [0.65105758, 0.34894242, 0.        ],\n",
       "       [0.81627275, 0.18372725, 0.        ],\n",
       "       [0.16419501, 0.83580499, 1.        ],\n",
       "       [0.87720636, 0.12279364, 0.        ],\n",
       "       [0.20487311, 0.79512689, 1.        ],\n",
       "       [0.35630168, 0.64369832, 1.        ],\n",
       "       [0.06912212, 0.93087788, 1.        ],\n",
       "       [0.86672698, 0.13327302, 0.        ],\n",
       "       [0.05086319, 0.94913681, 1.        ],\n",
       "       [0.04931734, 0.95068266, 1.        ],\n",
       "       [0.84681278, 0.15318722, 0.        ],\n",
       "       [0.87455636, 0.12544364, 0.        ],\n",
       "       [0.1257879 , 0.8742121 , 1.        ],\n",
       "       [0.88830249, 0.11169751, 0.        ],\n",
       "       [0.88830249, 0.11169751, 0.        ],\n",
       "       [0.76529405, 0.23470595, 0.        ],\n",
       "       [0.76792543, 0.23207457, 0.        ],\n",
       "       [0.88830249, 0.11169751, 0.        ],\n",
       "       [0.36965953, 0.63034047, 1.        ],\n",
       "       [0.92428709, 0.07571291, 0.        ],\n",
       "       [0.07111375, 0.92888625, 1.        ],\n",
       "       [0.89923662, 0.10076338, 0.        ],\n",
       "       [0.49320594, 0.50679406, 1.        ],\n",
       "       [0.03484931, 0.96515069, 1.        ],\n",
       "       [0.49874289, 0.50125711, 1.        ],\n",
       "       [0.90512931, 0.09487069, 0.        ],\n",
       "       [0.05185105, 0.94814895, 1.        ],\n",
       "       [0.90241705, 0.09758295, 0.        ],\n",
       "       [0.47018944, 0.52981056, 1.        ],\n",
       "       [0.87150063, 0.12849937, 0.        ],\n",
       "       [0.85878203, 0.14121797, 0.        ],\n",
       "       [0.85215855, 0.14784145, 0.        ],\n",
       "       [0.55034583, 0.44965417, 0.        ],\n",
       "       [0.89253786, 0.10746214, 0.        ],\n",
       "       [0.88300605, 0.11699395, 0.        ],\n",
       "       [0.89104336, 0.10895664, 0.        ],\n",
       "       [0.5960487 , 0.4039513 , 0.        ],\n",
       "       [0.34569904, 0.65430096, 1.        ],\n",
       "       [0.88793436, 0.11206564, 0.        ],\n",
       "       [0.92879607, 0.07120393, 0.        ],\n",
       "       [0.8756698 , 0.1243302 , 0.        ],\n",
       "       [0.80148397, 0.19851603, 0.        ],\n",
       "       [0.07415976, 0.92584024, 1.        ],\n",
       "       [0.93135214, 0.06864786, 0.        ],\n",
       "       [0.88831127, 0.11168873, 0.        ],\n",
       "       [0.86938102, 0.13061898, 0.        ],\n",
       "       [0.93648531, 0.06351469, 0.        ],\n",
       "       [0.67968357, 0.32031643, 0.        ],\n",
       "       [0.9883415 , 0.0116585 , 0.        ],\n",
       "       [0.88831127, 0.11168873, 0.        ],\n",
       "       [0.88375826, 0.11624174, 0.        ],\n",
       "       [0.68295725, 0.31704275, 0.        ],\n",
       "       [0.32253155, 0.67746845, 1.        ],\n",
       "       [0.67837966, 0.32162034, 0.        ],\n",
       "       [0.03484931, 0.96515069, 1.        ],\n",
       "       [0.54546431, 0.45453569, 0.        ],\n",
       "       [0.26483475, 0.73516525, 1.        ],\n",
       "       [0.56042417, 0.43957583, 0.        ],\n",
       "       [0.42971758, 0.57028242, 1.        ],\n",
       "       [0.65160467, 0.34839533, 0.        ],\n",
       "       [0.25193316, 0.74806684, 1.        ],\n",
       "       [0.81364686, 0.18635314, 0.        ],\n",
       "       [0.89600151, 0.10399849, 0.        ],\n",
       "       [0.19694734, 0.80305266, 1.        ],\n",
       "       [0.09109476, 0.90890524, 1.        ],\n",
       "       [0.85215855, 0.14784145, 0.        ],\n",
       "       [0.88200924, 0.11799076, 0.        ],\n",
       "       [0.89869853, 0.10130147, 0.        ],\n",
       "       [0.90834026, 0.09165974, 0.        ],\n",
       "       [0.33297561, 0.66702439, 1.        ],\n",
       "       [0.92433179, 0.07566821, 0.        ],\n",
       "       [0.76629763, 0.23370237, 0.        ],\n",
       "       [0.08149458, 0.91850542, 1.        ],\n",
       "       [0.83157433, 0.16842567, 0.        ],\n",
       "       [0.57094595, 0.42905405, 0.        ],\n",
       "       [0.36928253, 0.63071747, 1.        ],\n",
       "       [0.36287107, 0.63712893, 1.        ],\n",
       "       [0.87726151, 0.12273849, 0.        ],\n",
       "       [0.22189777, 0.77810223, 1.        ],\n",
       "       [0.1189601 , 0.8810399 , 1.        ],\n",
       "       [0.51123321, 0.48876679, 0.        ],\n",
       "       [0.86691672, 0.13308328, 0.        ],\n",
       "       [0.2488561 , 0.7511439 , 1.        ],\n",
       "       [0.30956986, 0.69043014, 1.        ],\n",
       "       [0.85004788, 0.14995212, 0.        ],\n",
       "       [0.2076384 , 0.7923616 , 1.        ],\n",
       "       [0.9086981 , 0.0913019 , 0.        ],\n",
       "       [0.33305707, 0.66694293, 1.        ],\n",
       "       [0.61951755, 0.38048245, 0.        ],\n",
       "       [0.34851491, 0.65148509, 1.        ],\n",
       "       [0.1161404 , 0.8838596 , 1.        ],\n",
       "       [0.69082384, 0.30917616, 0.        ],\n",
       "       [0.90832113, 0.09167887, 0.        ],\n",
       "       [0.10662461, 0.89337539, 1.        ],\n",
       "       [0.88834807, 0.11165193, 0.        ],\n",
       "       [0.14534106, 0.85465894, 1.        ],\n",
       "       [0.74955978, 0.25044022, 0.        ],\n",
       "       [0.75932786, 0.24067214, 0.        ],\n",
       "       [0.60204805, 0.39795195, 0.        ],\n",
       "       [0.93771624, 0.06228376, 0.        ],\n",
       "       [0.85877507, 0.14122493, 0.        ],\n",
       "       [0.45396164, 0.54603836, 1.        ],\n",
       "       [0.37238942, 0.62761058, 1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)], axis=1)\n",
    "pred_proba_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이진화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진화\n",
    "custom_threshold = 0.4\n",
    "pred_proba_1 = pred_proba[:, 1 ].reshape(-1,1) #새로운 예측값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정밀도, 재현율의 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99 19]\n",
      " [10 51]]\n",
      "********************\n",
      "0.8379888268156425 0.7285714285714285 0.8360655737704918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "binarizer = Binarizer(threshold = custom_threshold).fit(pred_proba_1) #새로운 예측값으로 이진화한 예측값\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[104  14]\n",
    " [ 13  48]]\n",
    "********************\n",
    "0.8491620111731844 0.7741935483870968 0.7868852459016393"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1-score\n",
    "\n",
    "재현율과 정밀도의 조화 평균 : 그 모델의 전체적인 성능을 볼 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7804878048780488"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC (Receiver Operation Characteristics) Curv\n",
    "\n",
    "민감도 어떻게 달라지는지 보는 지표 (=재현율, 실제 양성을 맞춘 비율)\n",
    "거짓긍정율 = 1- 특이도\n",
    "\n",
    "좌측상단 > 1에 가까울 수록 좋은 모델\n",
    "\n",
    "ROC-AUC : ROC 곡선 아래 면적값, 더 클 수록 좋은 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53842967, 0.12141982, 0.12279261, 0.11719051, 0.14505395,\n",
       "       0.11770789, 0.11165193, 0.79093173, 0.21752612, 0.6299874 ,\n",
       "       0.10012492, 0.12526568, 0.12279855, 0.11169751, 0.5647479 ,\n",
       "       0.14117124, 0.09632136, 0.2668604 , 0.27580414, 0.82750443,\n",
       "       0.24663308, 0.38050318, 0.14554527, 0.18494812, 0.11206564,\n",
       "       0.23470595, 0.1403271 , 0.07395373, 0.28072376, 0.30515505,\n",
       "       0.94734442, 0.81770518, 0.12671018, 0.8256362 , 0.3996279 ,\n",
       "       0.23470595, 0.07233564, 0.61152796, 0.05304285, 0.10397129,\n",
       "       0.35038675, 0.08316088, 0.82207232, 0.70792142, 0.6303243 ,\n",
       "       0.63034047, 0.9186499 , 0.35636701, 0.94893904, 0.11209994,\n",
       "       0.59419868, 0.11169751, 0.132921  , 0.72502006, 0.30972567,\n",
       "       0.19656787, 0.22648751, 0.12279364, 0.15439358, 0.43270567,\n",
       "       0.2804339 , 0.10093987, 0.54660071, 0.51356652, 0.44452222,\n",
       "       0.09463169, 0.66700991, 0.59421104, 0.95192387, 0.14784176,\n",
       "       0.12917258, 0.16867832, 0.10397352, 0.94792299, 0.1987446 ,\n",
       "       0.11169751, 0.34894242, 0.18372725, 0.83580499, 0.12279364,\n",
       "       0.79512689, 0.64369832, 0.93087788, 0.13327302, 0.94913681,\n",
       "       0.95068266, 0.15318722, 0.12544364, 0.8742121 , 0.11169751,\n",
       "       0.11169751, 0.23470595, 0.23207457, 0.11169751, 0.63034047,\n",
       "       0.07571291, 0.92888625, 0.10076338, 0.50679406, 0.96515069,\n",
       "       0.50125711, 0.09487069, 0.94814895, 0.09758295, 0.52981056,\n",
       "       0.12849937, 0.14121797, 0.14784145, 0.44965417, 0.10746214,\n",
       "       0.11699395, 0.10895664, 0.4039513 , 0.65430096, 0.11206564,\n",
       "       0.07120393, 0.1243302 , 0.19851603, 0.92584024, 0.06864786,\n",
       "       0.11168873, 0.13061898, 0.06351469, 0.32031643, 0.0116585 ,\n",
       "       0.11168873, 0.11624174, 0.31704275, 0.67746845, 0.32162034,\n",
       "       0.96515069, 0.45453569, 0.73516525, 0.43957583, 0.57028242,\n",
       "       0.34839533, 0.74806684, 0.18635314, 0.10399849, 0.80305266,\n",
       "       0.90890524, 0.14784145, 0.11799076, 0.10130147, 0.09165974,\n",
       "       0.66702439, 0.07566821, 0.23370237, 0.91850542, 0.16842567,\n",
       "       0.42905405, 0.63071747, 0.63712893, 0.12273849, 0.77810223,\n",
       "       0.8810399 , 0.48876679, 0.13308328, 0.7511439 , 0.69043014,\n",
       "       0.14995212, 0.7923616 , 0.0913019 , 0.66694293, 0.38048245,\n",
       "       0.65148509, 0.8838596 , 0.30917616, 0.09167887, 0.89337539,\n",
       "       0.11165193, 0.85465894, 0.25044022, 0.24067214, 0.39795195,\n",
       "       0.06228376, 0.14122493, 0.54603836, 0.62761058])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]\n",
    "pred_proba_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22ab34840d0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "\n",
    "#시각화\n",
    "plt.plot(fprs,tprs, label='ROC' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902542372881356"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, pred_proba_class1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델1의 ROC-AUC = 0.92 - 모델의 판별성능이 우수\n",
    "모델2의 ROC-AUC = 0.78 - 모델1보다 성능이 낮다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
