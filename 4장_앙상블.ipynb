{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperopt.__version__ 0.2.7\n",
      "sklearn.__version__ 1.0.2\n",
      "pandas.__version__ 1.3.5\n",
      "xgboost.__version__ 1.5.0\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "\n",
    "print(\"hyperopt.__version__\", hyperopt.__version__)\n",
    "\n",
    "import sklearn\n",
    "\n",
    "print(\"sklearn.__version__\", sklearn.__version__)\n",
    "#pip install scikit-learn==1.0.2  다운그레이드 해서 테스트하기\n",
    "\n",
    "import pandas\n",
    "print(\"pandas.__version__\", pandas.__version__)\n",
    "#pip install pandas==1.3.5\n",
    "\n",
    "import xgboost\n",
    "print(\"xgboost.__version__\", xgboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "X_features =  dataset.data\n",
    "y_label = dataset.target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=X_features, columns=dataset.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = y_label\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. Python native XGBoost\n",
    "#2. sklearn.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = df.iloc[:, :-1]\n",
    "y_label = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련 8: 시험 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size=0.2, random_state=156 )\n",
    "\n",
    "#훈련9 : 검증 1\n",
    "X_tr,  X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=156 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = xgb.DMatrix(data=X_tr, label=y_tr) \n",
    "dval = xgb.DMatrix(data=X_val, label=y_val) \n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth':3,\n",
    "    'eta':0.05,\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'logloss'\n",
    "}\n",
    "num_rounds = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.65016\teval-logloss:0.66183\n",
      "[1]\ttrain-logloss:0.61131\teval-logloss:0.63609\n",
      "[2]\ttrain-logloss:0.57563\teval-logloss:0.61144\n",
      "[3]\ttrain-logloss:0.54310\teval-logloss:0.59204\n",
      "[4]\ttrain-logloss:0.51323\teval-logloss:0.57329\n",
      "[5]\ttrain-logloss:0.48447\teval-logloss:0.55037\n",
      "[6]\ttrain-logloss:0.45796\teval-logloss:0.52929\n",
      "[7]\ttrain-logloss:0.43436\teval-logloss:0.51534\n",
      "[8]\ttrain-logloss:0.41150\teval-logloss:0.49718\n",
      "[9]\ttrain-logloss:0.39027\teval-logloss:0.48154\n",
      "[10]\ttrain-logloss:0.37128\teval-logloss:0.46990\n",
      "[11]\ttrain-logloss:0.35254\teval-logloss:0.45474\n",
      "[12]\ttrain-logloss:0.33528\teval-logloss:0.44229\n",
      "[13]\ttrain-logloss:0.31893\teval-logloss:0.42961\n",
      "[14]\ttrain-logloss:0.30439\teval-logloss:0.42065\n",
      "[15]\ttrain-logloss:0.29000\teval-logloss:0.40958\n",
      "[16]\ttrain-logloss:0.27651\teval-logloss:0.39887\n",
      "[17]\ttrain-logloss:0.26389\teval-logloss:0.39050\n",
      "[18]\ttrain-logloss:0.25210\teval-logloss:0.38254\n",
      "[19]\ttrain-logloss:0.24123\teval-logloss:0.37393\n",
      "[20]\ttrain-logloss:0.23076\teval-logloss:0.36789\n",
      "[21]\ttrain-logloss:0.22091\teval-logloss:0.36017\n",
      "[22]\ttrain-logloss:0.21155\teval-logloss:0.35421\n",
      "[23]\ttrain-logloss:0.20263\teval-logloss:0.34683\n",
      "[24]\ttrain-logloss:0.19434\teval-logloss:0.34111\n",
      "[25]\ttrain-logloss:0.18637\teval-logloss:0.33634\n",
      "[26]\ttrain-logloss:0.17875\teval-logloss:0.33082\n",
      "[27]\ttrain-logloss:0.17167\teval-logloss:0.32675\n",
      "[28]\ttrain-logloss:0.16481\teval-logloss:0.32099\n",
      "[29]\ttrain-logloss:0.15835\teval-logloss:0.31671\n",
      "[30]\ttrain-logloss:0.15225\teval-logloss:0.31277\n",
      "[31]\ttrain-logloss:0.14650\teval-logloss:0.30882\n",
      "[32]\ttrain-logloss:0.14102\teval-logloss:0.30437\n",
      "[33]\ttrain-logloss:0.13590\teval-logloss:0.30103\n",
      "[34]\ttrain-logloss:0.13109\teval-logloss:0.29794\n",
      "[35]\ttrain-logloss:0.12647\teval-logloss:0.29499\n",
      "[36]\ttrain-logloss:0.12197\teval-logloss:0.29295\n",
      "[37]\ttrain-logloss:0.11784\teval-logloss:0.29043\n",
      "[38]\ttrain-logloss:0.11379\teval-logloss:0.28927\n",
      "[39]\ttrain-logloss:0.10994\teval-logloss:0.28578\n",
      "[40]\ttrain-logloss:0.10638\teval-logloss:0.28364\n",
      "[41]\ttrain-logloss:0.10302\teval-logloss:0.28183\n",
      "[42]\ttrain-logloss:0.09963\teval-logloss:0.28005\n",
      "[43]\ttrain-logloss:0.09649\teval-logloss:0.27972\n",
      "[44]\ttrain-logloss:0.09359\teval-logloss:0.27744\n",
      "[45]\ttrain-logloss:0.09080\teval-logloss:0.27542\n",
      "[46]\ttrain-logloss:0.08807\teval-logloss:0.27504\n",
      "[47]\ttrain-logloss:0.08541\teval-logloss:0.27458\n",
      "[48]\ttrain-logloss:0.08299\teval-logloss:0.27348\n",
      "[49]\ttrain-logloss:0.08035\teval-logloss:0.27247\n",
      "[50]\ttrain-logloss:0.07786\teval-logloss:0.27163\n",
      "[51]\ttrain-logloss:0.07550\teval-logloss:0.27094\n",
      "[52]\ttrain-logloss:0.07344\teval-logloss:0.26967\n",
      "[53]\ttrain-logloss:0.07147\teval-logloss:0.27008\n",
      "[54]\ttrain-logloss:0.06964\teval-logloss:0.26890\n",
      "[55]\ttrain-logloss:0.06766\teval-logloss:0.26854\n",
      "[56]\ttrain-logloss:0.06592\teval-logloss:0.26900\n",
      "[57]\ttrain-logloss:0.06433\teval-logloss:0.26790\n",
      "[58]\ttrain-logloss:0.06259\teval-logloss:0.26663\n",
      "[59]\ttrain-logloss:0.06107\teval-logloss:0.26743\n",
      "[60]\ttrain-logloss:0.05957\teval-logloss:0.26610\n",
      "[61]\ttrain-logloss:0.05817\teval-logloss:0.26644\n",
      "[62]\ttrain-logloss:0.05691\teval-logloss:0.26673\n",
      "[63]\ttrain-logloss:0.05550\teval-logloss:0.26550\n",
      "[64]\ttrain-logloss:0.05422\teval-logloss:0.26443\n",
      "[65]\ttrain-logloss:0.05311\teval-logloss:0.26500\n",
      "[66]\ttrain-logloss:0.05207\teval-logloss:0.26591\n",
      "[67]\ttrain-logloss:0.05093\teval-logloss:0.26501\n",
      "[68]\ttrain-logloss:0.04976\teval-logloss:0.26435\n",
      "[69]\ttrain-logloss:0.04872\teval-logloss:0.26360\n",
      "[70]\ttrain-logloss:0.04776\teval-logloss:0.26319\n",
      "[71]\ttrain-logloss:0.04680\teval-logloss:0.26255\n",
      "[72]\ttrain-logloss:0.04580\teval-logloss:0.26204\n",
      "[73]\ttrain-logloss:0.04484\teval-logloss:0.26254\n",
      "[74]\ttrain-logloss:0.04388\teval-logloss:0.26289\n",
      "[75]\ttrain-logloss:0.04309\teval-logloss:0.26249\n",
      "[76]\ttrain-logloss:0.04224\teval-logloss:0.26217\n",
      "[77]\ttrain-logloss:0.04133\teval-logloss:0.26166\n",
      "[78]\ttrain-logloss:0.04050\teval-logloss:0.26179\n",
      "[79]\ttrain-logloss:0.03967\teval-logloss:0.26103\n",
      "[80]\ttrain-logloss:0.03877\teval-logloss:0.26094\n",
      "[81]\ttrain-logloss:0.03806\teval-logloss:0.26148\n",
      "[82]\ttrain-logloss:0.03740\teval-logloss:0.26054\n",
      "[83]\ttrain-logloss:0.03676\teval-logloss:0.25967\n",
      "[84]\ttrain-logloss:0.03605\teval-logloss:0.25905\n",
      "[85]\ttrain-logloss:0.03545\teval-logloss:0.26007\n",
      "[86]\ttrain-logloss:0.03488\teval-logloss:0.25984\n",
      "[87]\ttrain-logloss:0.03425\teval-logloss:0.25933\n",
      "[88]\ttrain-logloss:0.03361\teval-logloss:0.25932\n",
      "[89]\ttrain-logloss:0.03311\teval-logloss:0.26002\n",
      "[90]\ttrain-logloss:0.03260\teval-logloss:0.25936\n",
      "[91]\ttrain-logloss:0.03202\teval-logloss:0.25886\n",
      "[92]\ttrain-logloss:0.03152\teval-logloss:0.25918\n",
      "[93]\ttrain-logloss:0.03107\teval-logloss:0.25865\n",
      "[94]\ttrain-logloss:0.03049\teval-logloss:0.25951\n",
      "[95]\ttrain-logloss:0.03007\teval-logloss:0.26091\n",
      "[96]\ttrain-logloss:0.02963\teval-logloss:0.26014\n",
      "[97]\ttrain-logloss:0.02913\teval-logloss:0.25974\n",
      "[98]\ttrain-logloss:0.02866\teval-logloss:0.25937\n",
      "[99]\ttrain-logloss:0.02829\teval-logloss:0.25893\n",
      "[100]\ttrain-logloss:0.02789\teval-logloss:0.25928\n",
      "[101]\ttrain-logloss:0.02751\teval-logloss:0.25955\n",
      "[102]\ttrain-logloss:0.02714\teval-logloss:0.25901\n",
      "[103]\ttrain-logloss:0.02668\teval-logloss:0.25991\n",
      "[104]\ttrain-logloss:0.02634\teval-logloss:0.25950\n",
      "[105]\ttrain-logloss:0.02594\teval-logloss:0.25924\n",
      "[106]\ttrain-logloss:0.02556\teval-logloss:0.25901\n",
      "[107]\ttrain-logloss:0.02522\teval-logloss:0.25738\n",
      "[108]\ttrain-logloss:0.02492\teval-logloss:0.25702\n",
      "[109]\ttrain-logloss:0.02453\teval-logloss:0.25789\n",
      "[110]\ttrain-logloss:0.02418\teval-logloss:0.25770\n",
      "[111]\ttrain-logloss:0.02384\teval-logloss:0.25842\n",
      "[112]\ttrain-logloss:0.02356\teval-logloss:0.25810\n",
      "[113]\ttrain-logloss:0.02322\teval-logloss:0.25848\n",
      "[114]\ttrain-logloss:0.02290\teval-logloss:0.25833\n",
      "[115]\ttrain-logloss:0.02260\teval-logloss:0.25820\n",
      "[116]\ttrain-logloss:0.02229\teval-logloss:0.25905\n",
      "[117]\ttrain-logloss:0.02204\teval-logloss:0.25878\n",
      "[118]\ttrain-logloss:0.02176\teval-logloss:0.25728\n",
      "[119]\ttrain-logloss:0.02149\teval-logloss:0.25722\n",
      "[120]\ttrain-logloss:0.02119\teval-logloss:0.25764\n",
      "[121]\ttrain-logloss:0.02095\teval-logloss:0.25761\n",
      "[122]\ttrain-logloss:0.02067\teval-logloss:0.25832\n",
      "[123]\ttrain-logloss:0.02045\teval-logloss:0.25808\n",
      "[124]\ttrain-logloss:0.02023\teval-logloss:0.25855\n",
      "[125]\ttrain-logloss:0.01998\teval-logloss:0.25714\n",
      "[126]\ttrain-logloss:0.01973\teval-logloss:0.25587\n",
      "[127]\ttrain-logloss:0.01946\teval-logloss:0.25640\n",
      "[128]\ttrain-logloss:0.01927\teval-logloss:0.25685\n",
      "[129]\ttrain-logloss:0.01908\teval-logloss:0.25665\n",
      "[130]\ttrain-logloss:0.01886\teval-logloss:0.25712\n",
      "[131]\ttrain-logloss:0.01863\teval-logloss:0.25609\n",
      "[132]\ttrain-logloss:0.01839\teval-logloss:0.25649\n",
      "[133]\ttrain-logloss:0.01816\teval-logloss:0.25789\n",
      "[134]\ttrain-logloss:0.01802\teval-logloss:0.25811\n",
      "[135]\ttrain-logloss:0.01785\teval-logloss:0.25794\n",
      "[136]\ttrain-logloss:0.01763\teval-logloss:0.25876\n",
      "[137]\ttrain-logloss:0.01748\teval-logloss:0.25884\n",
      "[138]\ttrain-logloss:0.01732\teval-logloss:0.25867\n",
      "[139]\ttrain-logloss:0.01719\teval-logloss:0.25876\n",
      "[140]\ttrain-logloss:0.01696\teval-logloss:0.25987\n",
      "[141]\ttrain-logloss:0.01681\teval-logloss:0.25960\n",
      "[142]\ttrain-logloss:0.01669\teval-logloss:0.25982\n",
      "[143]\ttrain-logloss:0.01656\teval-logloss:0.25992\n",
      "[144]\ttrain-logloss:0.01638\teval-logloss:0.26035\n",
      "[145]\ttrain-logloss:0.01623\teval-logloss:0.26055\n",
      "[146]\ttrain-logloss:0.01606\teval-logloss:0.26092\n",
      "[147]\ttrain-logloss:0.01589\teval-logloss:0.26137\n",
      "[148]\ttrain-logloss:0.01572\teval-logloss:0.25999\n",
      "[149]\ttrain-logloss:0.01557\teval-logloss:0.26028\n",
      "[150]\ttrain-logloss:0.01546\teval-logloss:0.26048\n",
      "[151]\ttrain-logloss:0.01531\teval-logloss:0.26142\n",
      "[152]\ttrain-logloss:0.01515\teval-logloss:0.26188\n",
      "[153]\ttrain-logloss:0.01501\teval-logloss:0.26227\n",
      "[154]\ttrain-logloss:0.01486\teval-logloss:0.26287\n",
      "[155]\ttrain-logloss:0.01476\teval-logloss:0.26299\n",
      "[156]\ttrain-logloss:0.01461\teval-logloss:0.26346\n",
      "[157]\ttrain-logloss:0.01448\teval-logloss:0.26379\n",
      "[158]\ttrain-logloss:0.01434\teval-logloss:0.26306\n",
      "[159]\ttrain-logloss:0.01424\teval-logloss:0.26237\n",
      "[160]\ttrain-logloss:0.01410\teval-logloss:0.26251\n",
      "[161]\ttrain-logloss:0.01401\teval-logloss:0.26265\n",
      "[162]\ttrain-logloss:0.01392\teval-logloss:0.26264\n",
      "[163]\ttrain-logloss:0.01380\teval-logloss:0.26250\n",
      "[164]\ttrain-logloss:0.01372\teval-logloss:0.26264\n",
      "[165]\ttrain-logloss:0.01359\teval-logloss:0.26255\n",
      "[166]\ttrain-logloss:0.01350\teval-logloss:0.26188\n",
      "[167]\ttrain-logloss:0.01342\teval-logloss:0.26203\n",
      "[168]\ttrain-logloss:0.01331\teval-logloss:0.26190\n",
      "[169]\ttrain-logloss:0.01319\teval-logloss:0.26184\n",
      "[170]\ttrain-logloss:0.01312\teval-logloss:0.26133\n",
      "[171]\ttrain-logloss:0.01304\teval-logloss:0.26148\n",
      "[172]\ttrain-logloss:0.01297\teval-logloss:0.26157\n",
      "[173]\ttrain-logloss:0.01285\teval-logloss:0.26253\n",
      "[174]\ttrain-logloss:0.01278\teval-logloss:0.26229\n",
      "[175]\ttrain-logloss:0.01267\teval-logloss:0.26086\n",
      "[176]\ttrain-logloss:0.01258\teval-logloss:0.26103\n"
     ]
    }
   ],
   "source": [
    "eval_list = [(dtr, 'train'), (dval,'eval')]\n",
    "\n",
    "xgb_model = xgb.train(params=params, dtrain=dtr, num_boost_round=num_rounds,\\\n",
    "                early_stopping_rounds=50, evals=eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
